from __future__ import annotations

import abc
import typing as T

import torch
import torch.nn as nn
import typing_extensions as TX
from tensordict import TensorDictBase

from ..constants import DEBUG, KEY_INDEX
from .base_stage import Stage


class GateModule(nn.Module):
    """
    A module that performs gating of observations, returns a mask for candidates and
    detections.
    """

    @abc.abstractmethod
    @TX.override
    def forward(
        self, ctx: TensorDictBase, cs: TensorDictBase, ds: TensorDictBase  # noqa: U100
    ) -> T.Tuple[torch.Tensor, torch.Tensor]:
        raise NotImplementedError()


class Gate(Stage):
    """
    A stage that performs gating of observations.
    """

    def __init__(self, gate: nn.Module, then: T.Sequence[Stage]):
        # TODO: required fields?
        super().__init__()
        self.gate = gate
        self.then = nn.ModuleList(then)

    def __repr__(self) -> str:
        return f"{type(self).__name__}(gate={self.gate}, then={self.then})"

    __str__ = __repr__

    @TX.override
    def forward(
        self,
        ctx: TensorDictBase,
        cs: TensorDictBase,
        ds: TensorDictBase,
    ) -> T.Tuple[TensorDictBase, TensorDictBase]:
        # Perform gating
        cs_mask, ds_mask = self.gate(ctx, cs, ds)
        cs_gated = cs._get_sub_tensordict(cs_mask)
        ds_gated = ds._get_sub_tensordict(ds_mask)

        # Perform subsequent stages on only the subset
        for stage in self.then:
            if cs_gated.batch_size[0] == 0 or ds_gated.batch_size[0] == 0:
                break
            cs_gated, ds_gated = stage(ctx, cs_gated, ds_gated)

        # Continue to next stage, but remove all observations that have been assigned
        # already
        cs_index = cs.get(KEY_INDEX)
        cs_unmatched = cs._get_sub_tensordict(cs_index < 0)

        ds_index = ds.get(KEY_INDEX)
        ds_unmatched = ds._get_sub_tensordict(ds_index >= 0)

        return cs_unmatched, ds_unmatched
